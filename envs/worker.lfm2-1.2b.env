# NATS Configuration
NATS_URL=nats://127.0.0.1:5700
STREAM_NAME=INFER_LFM2_1_2B
SUBJECT=inference.request.lfm2-1.2b
QUEUE_DURABLE=lfm2-1-2b-wq
QUEUE_GROUP=workers
RESPONSE_PREFIX=inference.reply
QUEUE_MAX_MSGS=2000
QUEUE_MAX_AGE=30s
ACK_WAIT=30s
MAX_DELIVER=5
MAX_ACK_PENDING=64

# Worker Configuration
WORKER_CONCURRENCY=2

# HTTP Configuration
HTTP_ADDR=:5775

# Model Configuration
MODEL_NAME=lfm2-1.2b
MODEL_URL=https://huggingface.co/LiquidAI/LFM2-1.2B-Tool-GGUF/resolve/main/LFM2-1.2B-Tool-Q4_K_M.gguf
MODEL_PATH=data/models/lfm2-1.2b/model.gguf
MODEL_FORMAT=template
MODEL_THREADS=8
CTX_SIZE=8192

# Data Directory Configuration  
DATA_DIR=data

# Database Configuration
DB_PATH=data/logs/lfm2-1.2b.sqlite

# Monitoring Configuration
MONITORING_TOPIC=monitoring.inference
BACKPRESSURE_THRESHOLD=5