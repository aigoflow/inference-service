# NATS Configuration
NATS_URL=nats://127.0.0.1:4222
STREAM_NAME=INFER_GPT_OSS_20B
SUBJECT=inference.request.gpt-oss-20b
QUEUE_DURABLE=gpt-oss-20b-wq
QUEUE_GROUP=workers
RESPONSE_PREFIX=inference.reply
QUEUE_MAX_MSGS=2000
QUEUE_MAX_AGE=30s
ACK_WAIT=30s
MAX_DELIVER=5
MAX_ACK_PENDING=64

# Worker Configuration
WORKER_CONCURRENCY=2

# HTTP Configuration
HTTP_ADDR=:5772

# Model Configuration
MODEL_NAME=gpt-oss-20b
MODEL_URL=https://huggingface.co/bartowski/openai_gpt-oss-20b-GGUF/resolve/main/openai_gpt-oss-20b-MXFP4.gguf
MODEL_PATH=data/models/gpt-oss-20b/model.gguf
MODEL_THREADS=8
CTX_SIZE=8192

# Data Directory Configuration  
DATA_DIR=data

# Database Configuration
DB_PATH=data/logs/gpt-oss-20b.sqlite